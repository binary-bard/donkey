{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 160\n",
    "img_height = 120\n",
    "image_size=(img_height, img_width)\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_height, img_width)\n",
    "else:\n",
    "    input_shape = (img_height, img_width, 3)\n",
    "    \n",
    "print(input_shape)\n",
    "nb_train_samples = 10000\n",
    "nb_validation_samples = 4000\n",
    "# Path to datadir where train, val and test directories reside\n",
    "datadir = 'Jun21'\n",
    "\n",
    "batch_size = 20\n",
    "nb_angles = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        datadir + '/train',\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "#Validation Generator\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        datadir + '/val',\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "print(val_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python2 uses iteritems() while Python3 uses items()\n",
    "inv_map = {v: k for k, v in train_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 50\n",
    "nb_filters=16\n",
    "kernel_size=(3,3)\n",
    "pool_size=(2,2)\n",
    "#img = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = '1'\n",
    "model_file = 'models/out15_' + datadir + '_' + idx + '.h5'\n",
    "weights_file = 'weights/out15_' + datadir + '_' + idx + '.h5'\n",
    "got_weights = False\n",
    "save_model = True\n",
    "try:\n",
    "    model = load_model(model_file)\n",
    "    print('Model loaded')\n",
    "    got_weights = True\n",
    "    save_model = False\n",
    "except:\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(nb_filters, kernel_size, input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(2*nb_filters, kernel_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(2*nb_filters, kernel_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(4*nb_filters, kernel_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(nb_angles, activation = 'softmax', name = 'angle_out'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    print('Model compiled')\n",
    "    try:\n",
    "        model.load_weights(weights_file)\n",
    "        got_weights = True\n",
    "        print('Weights loaded')\n",
    "    except:\n",
    "        got_weights = False\n",
    "\n",
    "print(got_weights)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = None\n",
    "if not got_weights:\n",
    "    steps_pe = 200\n",
    "    valSteps = 50\n",
    "    hist = model.fit_generator(train_generator, steps_per_epoch=steps_pe,\n",
    "              epochs=nb_epoch, validation_data=val_generator,\n",
    "              validation_steps=valSteps)\n",
    "\n",
    "    model.save_weights(weights_file)\n",
    "    save_model = True\n",
    "    print('Model trained and weights saved')\n",
    "\n",
    "if save_model:\n",
    "    model.save(model_file)\n",
    "    print('Model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(val_generator, steps=100)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if hist:\n",
    "    plt.close()\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.show()\n",
    "    plt.plot(hist.history['acc'])\n",
    "    plt.plot(hist.history['val_acc'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        datadir + '/test',\n",
    "        target_size=image_size,\n",
    "        batch_size=20,\n",
    "        class_mode=None)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notDone = True\n",
    "i = 0\n",
    "axis_font = {'size':'48'}\n",
    "while(notDone):\n",
    "  batch_X = test_generator.next()\n",
    "  #print(batch_X)\n",
    "  batch_y = model.predict_on_batch(batch_X)\n",
    "  #print(batch_y)\n",
    "  j = 0\n",
    "  f, axarr = plt.subplots(5, 4, figsize=(80, 60))\n",
    "  for (X, y) in zip(batch_X, batch_y):\n",
    "    #ax = plt.subplot(gl[j, i])\n",
    "    k = j % 5\n",
    "    l = j // 5\n",
    "    #print(k, l)\n",
    "    axarr[k, l].imshow(X)\n",
    "    idx = np.argmax(y)\n",
    "    txt = inv_map[idx] + ', ' + str(round(y[idx], 2))\n",
    "    axarr[k, l].text(0, 0, txt, **axis_font)\n",
    "    j += 1\n",
    "    if j >= 20:\n",
    "      break\n",
    "    #print(y)\n",
    "    #pause\n",
    "  i += 1\n",
    "  notDone = i < 5\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inv_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
